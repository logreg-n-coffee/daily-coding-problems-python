{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 395\n",
    "\n",
    "## Description\n",
    "\n",
    "This problem was asked by Robinhood.\n",
    "\n",
    "Given an array of strings, group anagrams together.\n",
    "\n",
    "For example, given the following array:\n",
    "\n",
    "`['eat', 'ate', 'apt', 'pat', 'tea', 'now']`\n",
    "\n",
    "Return:\n",
    "\n",
    "```python\n",
    "[['eat', 'ate', 'tea'],\n",
    " ['apt', 'pat'],\n",
    " ['now']]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def group_anagrams(words):\n",
    "    anagrams = defaultdict(list)\n",
    "\n",
    "    for word in words:\n",
    "        # count characters in word\n",
    "        char_count = [0] * 26\n",
    "        for char in word:\n",
    "            char_count[ord(char) - ord(\"a\")] += 1\n",
    "        # use the character count as the key\n",
    "        anagrams[tuple(char_count)].append(word)\n",
    "\n",
    "    # return the grouped anagrams\n",
    "    return list(anagrams.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['eat', 'ate', 'tea'], ['apt', 'pat'], ['now']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function with the provided example\n",
    "test_words = [\"eat\", \"ate\", \"apt\", \"pat\", \"tea\", \"now\"]\n",
    "group_anagrams(test_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improving the efficiency of the anagram grouping algorithm mainly revolves around reducing the time complexity associated with sorting each word, which is \\(O(n \\cdot k \\log k)\\) in the current approach. One way to do this is by using a character count instead of sorting. Here's how you can modify the approach:\n",
    "\n",
    "1. **Use Character Count as Key**: Instead of sorting each word, count the frequency of each character in the word. This can be represented as a tuple of 26 elements (assuming the English alphabet), where each element represents the count of a particular character (a-z) in the word. For example, 'aab' would be represented as (2, 1, 0, 0, ..., 0), indicating 2 'a's, 1 'b', and 0 of every other letter.\n",
    "\n",
    "2. **Hash Map for Grouping**: Use this tuple as the key in the hash map. Words that are anagrams of each other will have the same character count and thus the same key.\n",
    "\n",
    "This method avoids the \\(O(k \\log k)\\) sorting time for each word, replacing it with \\(O(k)\\) for counting characters, which can be significant, especially for longer words.\n",
    "\n",
    "Let's implement this improved method in Python:\n",
    "\n",
    "The more efficient method also correctly grouped the anagrams. The result is as follows:\n",
    "\n",
    "- \\[['eat', 'ate', 'tea'], ['apt', 'pat'], ['now']\\]\n",
    "\n",
    "This method is more efficient, especially for longer words, because it avoids the \\(O(k \\log k)\\) sorting time for each word and replaces it with \\(O(k)\\) for counting characters. Here's the updated complexity analysis:\n",
    "\n",
    "### Time Complexity\n",
    "\n",
    "1. **Iterating Through Each Word**: This remains \\(O(n)\\), where \\(n\\) is the number of words.\n",
    "\n",
    "2. **Counting Characters in Each Word**: The time to count characters in each word is \\(O(k)\\), where \\(k\\) is the average length of a word. Since this is done for each word, the total time for this step is \\(O(n \\cdot k)\\).\n",
    "\n",
    "3. **Inserting into a Hash Map**: The insertion into a hash map remains \\(O(1)\\) on average for each word, so this doesn't significantly change the overall time complexity.\n",
    "\n",
    "Overall, the time complexity is now \\(O(n \\cdot k)\\), which is an improvement over the previous \\(O(n \\cdot k \\log k)\\) when \\(k\\) is large.\n",
    "\n",
    "### Space Complexity\n",
    "\n",
    "The space complexity remains largely the same, \\(O(n \\cdot k)\\), because the space is primarily used to store the anagrams in the hash map and the output list. The character counts do not significantly add to the space complexity since they are of fixed size (26 for the English alphabet).\n",
    "\n",
    "In summary:\n",
    "\n",
    "- **Time Complexity**: \\(O(n \\cdot k)\\)\n",
    "- **Space Complexity**: \\(O(n \\cdot k)\\)\n",
    "\n",
    "This method is more efficient, particularly for large datasets with longer words.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
